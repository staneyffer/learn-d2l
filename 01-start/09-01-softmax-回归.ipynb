{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e48a3b0-39da-4044-a104-fd1dd2a394b5",
   "metadata": {},
   "source": [
    "## 回归 VS 分类\n",
    "- ### 回归估计一个连续值\n",
    "- ### 分类预测一个离散类别\n",
    "\n",
    "**MNIST：手写数字识别(10类)**\n",
    "\n",
    "**ImageNet: 自然物体分类(1000类）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120e919-ef45-4cee-abbd-19ee87b430c5",
   "metadata": {},
   "source": [
    "## 从回归到多类分类\n",
    "\n",
    "## 回归\n",
    "- 单连续数值输出\n",
    "- 自然区间 $\\mathbb R$\n",
    "- 跟真是的区别作为损失\n",
    "\n",
    "```mermaid\n",
    "graph BT\n",
    "x1((x1)) --> o1((o1))\n",
    "x2((x2)) --> o1((o1))\n",
    "x3((x3)) --> o1((o1))\n",
    "\n",
    "```\n",
    "\n",
    "## 分类\n",
    "- 通常多个输出\n",
    "- 输出$i$是预测为第$i$类的置信度\n",
    "```mermaid\n",
    "graph BT\n",
    "x1((x1)) --> o1((o1))\n",
    "x1((x1)) --> o2((o2))\n",
    "x1((x1)) --> o3((o3))\n",
    "\n",
    "x2((x2)) --> o1\n",
    "x2((x2)) --> o2\n",
    "x2((x2)) --> o3\n",
    "\n",
    "x3((x3)) --> o1\n",
    "x3((x3)) --> o2\n",
    "x3((x3)) --> o3\n",
    "\n",
    "x4((x4)) --> o1\n",
    "x4((x4)) --> o2\n",
    "x4((x4)) --> o3\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bf2bd-82a2-493b-a0ba-501804445370",
   "metadata": {},
   "source": [
    "## 从回归到多类分类-均方损失\n",
    "- ### 对类别进行一位有效编码\n",
    "$$\n",
    "\\pmb y = [y_1, y_2,...,y_n]^\\top\n",
    "y_i = \\begin{cases} 1 & \\text{if i = y} \\\\ 0 & \\text{otherwise} \\end{cases}\n",
    "$$\n",
    "\n",
    "- ### 使用均方损失训练\n",
    "- ### 最大值最为预测\n",
    "\n",
    "$$\\hat{y} = arg \\mathop{\\max}_i o_i$$\n",
    "\n",
    "- ### 需要更置信的识别正确类（大于量）\n",
    " $$\n",
    " \\pmb o_y - \\pmb o_i \\ge \\Delta(y, i)\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193179bf-5fb2-4fe0-bd2c-83a4334815e4",
   "metadata": {},
   "source": [
    "## 从回归到多类分类-校验比例\n",
    "\n",
    "- ### 输出匹配概率（非负，和为$1$）\n",
    "$$\n",
    "\\hat{\\pmb y} = \\text{softmax}(\\pmb o) \\\\\n",
    "\\hat{y_i} = \\frac{\\text{exp}(o_i)}{\\sum_k \\text{exp}(o_k)}\n",
    "$$\n",
    "\n",
    "- ### 概率$\\pmb y$和$\\hat{\\pmb y}$的区别作为损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6515f-5302-4c7e-af1c-84908cfa97c9",
   "metadata": {},
   "source": [
    "## Softmax和交叉熵损失\n",
    "- ### 交叉熵常用来衡量两个概率的区别\n",
    "$$\n",
    "\\pmb H(\\pmb p, \\pmb q) = \\sum_i -p_i \\text{log}(q_i)\n",
    "$$\n",
    "\n",
    "- ### 将它作为损失\n",
    "$$\n",
    "l(\\pmb y, \\hat{\\pmb y}) = -\\sum_i y_i \\text{log}\\hat{y_y}\n",
    "$$\n",
    "\n",
    "- ### 其梯度是真是概率和预测概率的区别\n",
    "$$\n",
    "\\partial_{o_i} l(\\pmb y, \\hat{\\pmb y}) = \\text{softmax}(\\pmb o)_i - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3280b5-29c0-4611-ac5a-1d4073df53ac",
   "metadata": {},
   "source": [
    "## 总结\n",
    "- ### Softmax回归是一个多类分类模型\n",
    "- ### 使用Softmax操作子得到每个类的预测置信度\n",
    "- ### 使用交叉熵来衡量预测和标号的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32663f74-3619-4c6e-a5de-736290deba8e",
   "metadata": {},
   "source": [
    "## TODO 损失函数的推导"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886e1f08-4f82-46c3-aa41-ab1d10af2557",
   "metadata": {},
   "source": [
    "## 梯度下降\n",
    "- ### 挑选一个初始值$w_0$\n",
    "- ### 重复迭代参数 $t = 1,2,3$\n",
    "$$\n",
    "\\pmb w_t = \\pmb w_{t-1} - \\eta \\frac{\\partial \\ell}{\\partial \\pmb w_{t-1}}\n",
    "$$\n",
    "- #### 沿梯度方向将增加损失函数值\n",
    "- #### 学习率（$\\eta$）：步长的超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4fe772-d3f0-4da4-8cf7-3cb6960fc21b",
   "metadata": {},
   "source": [
    "## 选择学习率\n",
    "\n",
    "- 不能太小（收敛比较慢）\n",
    "- 不能太大 （一直在震荡，无法达到最优解）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29e1a5-f64f-4167-9538-2b64ff84a467",
   "metadata": {},
   "source": [
    "## 小批量随机梯度下降\n",
    "- ### 在整个训练集上算梯度太贵（一个深度神经网络模型可能需要数分钟至数小时）\n",
    "- ### 我们可以随机采样$b$个样本$i_1, i_2,...,i_b$来近似损失\n",
    "$$\n",
    "\\frac{1}{b} \\sum_{i \\in \\pmb I_b} \\ell (\\pmb x_i, y_i, \\pmb w)\n",
    "$$\n",
    "\n",
    "其中, $b$是批量大小，另一个重要的超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6324b9-1f63-485f-8be8-a05cc041142a",
   "metadata": {},
   "source": [
    "## 选择批量大小\n",
    "### 不能太小\n",
    "每次计算量太小，不适合并行来最大利用计算资源\n",
    "\n",
    "### 不能太大\n",
    "内存消耗增加，浪费计算，例如如果所有样本都是相同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60530cc3-184d-492e-8945-c27f1b0d26af",
   "metadata": {},
   "source": [
    "## 总结\n",
    "- ### 梯度下降通过不断沿着反梯度方向更新参数求解\n",
    "- ### 小批量随机梯度下降是深度学习默认的求解算法\n",
    "- ### 两个重要的超参数是批量大小和学习率"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

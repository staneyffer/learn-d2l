{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8b5684",
   "metadata": {},
   "source": [
    "## 房价预测\n",
    "\n",
    "### 一个简化模型\n",
    "- ### 假设1：影响房价的关键因素是卧室个数，卫生间个数和居住面积，记为$x_1, x_2, x_3$\n",
    "- ### 假设2：成交价是关键因素的加权和\n",
    "$$\n",
    "y = w_1x_1 + w_2x_2 + w_3x_3 + b\n",
    "$$\n",
    "\n",
    "其中$b$是偏差，权重和偏差的实际值在后面决定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f956ce-0e8f-4a8c-a58a-a6bae33d0d2a",
   "metadata": {},
   "source": [
    "## 线性模型\n",
    "- ### 给定$n$维输入 $\\pmb x = [x_1,x_2,...,x_n]^\\top$\n",
    "- ### 线性模型有一个$n$维权重和一个标量偏差\n",
    "$$\n",
    "\\pmb w = [w_1,w_2,...,w_n]^\\top, b\n",
    "$$\n",
    "- ### 输出是输入的加权和\n",
    "$$\n",
    "\\pmb y = w_1x_1 + w_2x_2 + ... + w_nx_n + b\n",
    "$$\n",
    "- ### 向量版本: $y = \\langle \\pmb w, \\pmb x \\rangle + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e6923-a48b-45c0-b6a3-2069abb44b3d",
   "metadata": {},
   "source": [
    "## 线性模型可以看做单层神经网络\n",
    "\n",
    "```mermaid\n",
    "graph BT\n",
    "x1((x1))-->O1((o1))\n",
    "x2((x2))-->O1((o1))\n",
    "x3((x3))-->O1((o1))\n",
    "xd((xd))-->O1((o1))\n",
    "\n",
    "```\n",
    "\n",
    "其中$o_1$表示输出层，$x_1,x_2,...,x_d$是输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19a60b-9316-4b5a-9e6c-259eabeb57ef",
   "metadata": {},
   "source": [
    "## 衡量预估质量\n",
    "- ### 比较真实值和预估值，例如房屋的售价和估价\n",
    "- ### 假设$y$是真实值，$\\hat{y}$ 是估计值，我们可以比较\n",
    "$$\n",
    "\\ell (y, \\hat{y}) = \\frac{1}{2}(y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "**这个叫平方损失**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72362898-180c-4e0a-8baa-cdeeb9a87b40",
   "metadata": {},
   "source": [
    "## 训练数据\n",
    "- ### 收集一些数据点来决定参数（权重和偏差），例如过去6个月卖的房子\n",
    "- ### 这被称之为训练数据\n",
    "- ### 通常越多越好\n",
    "- ### 假设我们有$n$个样本，记\n",
    "$$\n",
    "\\pmb X = [\\pmb x_1, \\pmb x_2,..., \\pmb x_n]^\\top \\quad \\pmb y = [y_1,y_2,...,y_n]^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ba024-ad8b-4a39-a604-20d41a65d4fd",
   "metadata": {},
   "source": [
    "## 参数学习\n",
    "- ### 训练损失\n",
    "$$\n",
    "\\ell (\\pmb X, \\pmb y, \\pmb w, b) = \\frac{1}{2n} \\sum_{i=1}^n(y_i - \\langle \\pmb x_i, \\pmb w \\rangle - b)^2 = \\frac{1}{2n} \\begin{Vmatrix} y - \\pmb X \\pmb w - b \\end{Vmatrix} ^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31262ef3-5395-48a7-adad-e0102c1ac6b7",
   "metadata": {},
   "source": [
    "其中， \n",
    "$\\frac{1}{2}$来自于损失函数$\\frac{1}{2}(y-\\hat{y})^2$, $\\frac{1}{n}$表示求平均\n",
    "\n",
    "- ### 最小化损失来学习参数\n",
    "$$\n",
    "\\pmb w^{\\ast}, \\pmb b^{\\ast} = arg \\mathop{\\min}_{\\pmb w, b} \\ell(\\pmb X, \\pmb y, \\pmb w, b)\n",
    "$$\n",
    "\n",
    "我们的目标是找到一个$\\pmb w, b$使得我们的损失函数最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbc37d-f5da-4752-bae8-e95e35c5eef8",
   "metadata": {},
   "source": [
    "## 显示解\n",
    "线性模型有显示解\n",
    "\n",
    "- ### 将偏差加入权重 $\\pmb X \\gets [\\pmb X, 1] \\quad \\pmb w \\gets \\left[ \\begin{matrix} \\pmb w \\\\ b \\end{matrix} \\right]$\n",
    "$$\n",
    "\\ell (\\pmb X, \\pmb y, \\pmb w) = \\frac{1}{2n} \\begin{Vmatrix} \\pmb y - \\pmb X \\pmb w \\end{Vmatrix} ^2 \\\\\n",
    "\\frac{\\partial }{\\partial \\pmb w} \\ell(\\pmb X, \\pmb y, \\pmb w) = \\frac{1}{n}(\\pmb y - \\pmb X \\pmb w)^\\top \\pmb X\n",
    "$$\n",
    "\n",
    "其中，将一列全$1$的特征，加入到矩阵$\\pmb X$中，便能将$b$加入到参数$\\pmb w$中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e2299-93aa-49eb-a2d7-3c42a73f5db4",
   "metadata": {},
   "source": [
    "- ### 损失是凸函数，所以最优解满足（一定存在梯度为0的点)\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\pmb w} \\ell(\\pmb X, \\pmb y, \\pmb w) = 0 \\\\\n",
    "\\Leftrightarrow \\frac{1}{n}(\\pmb y - \\pmb X \\pmb w)^\\top \\pmb X = 0 \\\\\n",
    "\\Leftrightarrow \\pmb w ^{\\ast} = (\\pmb X^\\top \\pmb X)^{-1} \\pmb X^\\top \\pmb y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6f687-9719-4581-a784-71b6d5cc17e5",
   "metadata": {},
   "source": [
    "## 总结\n",
    "- ### 线性回归是对$n$维输入的加权，外加偏差\n",
    "- ### 使用平方损失来衡量预测值和真实值的差异\n",
    "- ### 线性回归有显示解\n",
    "- ### 线性回归可以看做是单层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c457880-8ac2-475c-802e-9369adc8a23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
